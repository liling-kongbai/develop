{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\kongbai\\\\study\\\\dataset\\\\book.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 87\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m feature, label\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m#文本预处理\u001b[39;00m\n\u001b[1;32m---> 87\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43mYuChuLi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtextYuChuLi\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mUsers\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mkongbai\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mstudy\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mdataset\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mbook.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     88\u001b[0m count \u001b[38;5;241m=\u001b[39m YuChuLi\u001b[38;5;241m.\u001b[39mconunt(text)\n\u001b[0;32m     89\u001b[0m charToIndexVocabulary, indexToCharVocabulary \u001b[38;5;241m=\u001b[39m YuChuLi\u001b[38;5;241m.\u001b[39mvocabulary(text)\n",
      "Cell \u001b[1;32mIn[1], line 13\u001b[0m, in \u001b[0;36mYuChuLi.textYuChuLi\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtextYuChuLi\u001b[39m(text):\n\u001b[1;32m---> 13\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m text:\n\u001b[0;32m     14\u001b[0m         text \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m     16\u001b[0m         \u001b[38;5;66;03m# 正则表达式匹配所有非字母和非空格的字符转为空格\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kongbai\\anaconda3\\envs\\myEnv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[1;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\kongbai\\\\study\\\\dataset\\\\book.txt'"
     ]
    }
   ],
   "source": [
    "# 导入相关库并设置所需全局变量\n",
    "import re\n",
    "from collections import Counter\n",
    "import torch\n",
    "from torch import nn\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    " \n",
    "# 定义并封装文本或字符串的预处理方法\n",
    "class YuChuLi:\n",
    "    # 文本预处理\n",
    "    @staticmethod\n",
    "    def textYuChuLi(text):\n",
    "        with open(text) as text:\n",
    "            text = text.read()\n",
    " \n",
    "            # 正则表达式匹配所有非字母和非空格的字符转为空格\n",
    "            text = re.sub(r'[^a-zA-Z\\s]', ' ', text)\n",
    "            # 替换连续空格为单个空格\n",
    "            text = re.sub(r'\\s+', ' ', text)\n",
    " \n",
    "            text = text.lower()\n",
    "        return text\n",
    " \n",
    "    # 字符串预处理\n",
    "    @staticmethod\n",
    "    def stringYuChuLi(string):\n",
    "        string = re.sub(r'[^a-zA-Z\\s]', ' ', string)\n",
    "        string = re.sub(r'\\s+', ' ', string)\n",
    "        string = string.lower()\n",
    "        return string\n",
    "    \n",
    "    # 统计字符串中空格和各种单词数量\n",
    "    @staticmethod\n",
    "    def conunt(string):\n",
    "        # 正则表达式匹配所有空格并统计\n",
    "        spacesCount = len(re.findall(r'\\s', string))\n",
    " \n",
    "        # 统计各种单词数量\n",
    "        string = string.split()\n",
    "        wordCount = Counter(string)\n",
    "        wordCount = wordCount.most_common()\n",
    "        print(f'空格：{spacesCount}个')\n",
    "        for word, count in wordCount:\n",
    "            print(f'{word}：{count}个')\n",
    "        \n",
    "    # 构建双向字典词表\n",
    "    @staticmethod\n",
    "    def vocabulary(string):\n",
    "        charToIndexVocabulary = dict()\n",
    "        indexToCharVocabulary = dict()\n",
    "        index = 0\n",
    "        for char in string:\n",
    "            if char not in charToIndexVocabulary.keys():\n",
    "                charToIndexVocabulary[char] = index\n",
    "                indexToCharVocabulary[index] = char\n",
    "                index += 1\n",
    "        return charToIndexVocabulary, indexToCharVocabulary\n",
    "    \n",
    "    # 字符序列串转数字序列\n",
    "    @staticmethod\n",
    "    def charToIndexTransform(string, charToIndex):\n",
    "        indexSequence = []\n",
    "        for char in string:\n",
    "            if char in charToIndex:\n",
    "                indexSequence.append(charToIndex[char])\n",
    "        return indexSequence\n",
    " \n",
    "    # 数字序列转字符序列\n",
    "    @staticmethod\n",
    "    def indexToCharTransform(index, indexToChar):\n",
    "        charSequence = []\n",
    "        for index in index:\n",
    "            if index in indexToChar:\n",
    "                charSequence.append(indexToChar[index])\n",
    "        return charSequence\n",
    " \n",
    "    # 截取序列获得样本\n",
    "    @staticmethod\n",
    "    def example(sequence, window):\n",
    "        feature, label= [], []\n",
    "        for i in range(len(sequence) - window  - 1):\n",
    "            feature.append(sequence[i : i + window])\n",
    "            label.append(sequence[i + window + 1])\n",
    "        return feature, label\n",
    " \n",
    "#文本预处理\n",
    "text = YuChuLi.textYuChuLi('C:\\\\Users\\\\kongbai\\\\study\\\\dataset\\\\book.txt')\n",
    "count = YuChuLi.conunt(text)\n",
    "charToIndexVocabulary, indexToCharVocabulary = YuChuLi.vocabulary(text)\n",
    "for key, value in charToIndexVocabulary.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "for key, value in indexToCharVocabulary.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "textIndexSequence = YuChuLi.charToIndexTransform(text, charToIndexVocabulary)\n",
    "window = 5\n",
    "feature, label = YuChuLi.example(textIndexSequence, window)\n",
    " \n",
    "# 文本预处理结果向量化并创建数据迭代器\n",
    "featureTensor = torch.tensor(feature, device=device)\n",
    "labelTensor = torch.tensor(label, device=device)\n",
    "tensorDataset = torch.utils.data.TensorDataset(featureTensor, labelTensor)\n",
    "batch_size = 64\n",
    "shuffle = True\n",
    "dataloader = torch.utils.data.DataLoader(tensorDataset, batch_size, shuffle)\n",
    " \n",
    "# 定义模型\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout, output_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.bilstm = nn.LSTM(hidden_size, hidden_size, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc1 = nn.Linear(hidden_size * 2, hidden_size // 2)\n",
    "        self.fc2 = nn.Linear(hidden_size // 2, hidden_size // 4)\n",
    "        self.fc3 = nn.Linear(hidden_size // 4, output_size)\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, _ = self.bilstm(x)\n",
    "        x = x[:, -1, :]\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        x = nn.functional.elu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = nn.functional.elu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    " \n",
    "# 设置初始化模型所需的参数并初始化模型\n",
    "input_size = output_size = len(charToIndexVocabulary)\n",
    "hidden_size = 32\n",
    "dropout = 0.4\n",
    "network = Net(input_size, hidden_size, dropout, output_size).to(device)\n",
    " \n",
    "# 定义损失函数和优化器并初始化所需参数\n",
    "Loss = nn.CrossEntropyLoss()\n",
    "lr = 0.005\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr)\n",
    " \n",
    "# 训练模型\n",
    "network.train()\n",
    "num_epochs = 2\n",
    "for epoch in range(num_epochs):\n",
    "    i = 1\n",
    "    for features, label in dataloader:\n",
    "        output = network(features)\n",
    "        loss = Loss(output, label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        i += 1\n",
    "        if i % 50 == 0:\n",
    "            print(f'第{epoch + 1}轮，第{i}个损失：{loss}')\n",
    "    print(f'第{epoch + 1}轮最后一次损失：{loss}')\n",
    " \n",
    "# 模型预测\n",
    "network.eval()\n",
    "window = 5\n",
    "num_steps = 100\n",
    "string = 'LiLing_KongBai'\n",
    "string = YuChuLi.stringYuChuLi(string)\n",
    "stringIndexSequence = YuChuLi.charToIndexTransform(string, charToIndexVocabulary)\n",
    "with torch.no_grad():\n",
    "    for i in range(num_steps):\n",
    "        example = torch.tensor(stringIndexSequence[-window :]).unsqueeze(0).to(device)\n",
    "        new_output = network(example)\n",
    "        predict_index = new_output.argmax(dim=1, keepdim=True)\n",
    "        stringIndexSequence.append(predict_index.item())\n",
    "predict_char = YuChuLi.indexToCharTransform(stringIndexSequence, indexToCharVocabulary)\n",
    "predict_char = ''.join(predict_char)\n",
    "print(predict_char)\n",
    " \n",
    "# 手动单步预测\n",
    "string2 = 'LiLing_KongBai'\n",
    "string2 = YuChuLi.stringYuChuLi(string2)\n",
    "stringIndexSequence2 = YuChuLi.charToIndexTransform(string2, charToIndexVocabulary)\n",
    "example2 = torch.tensor(stringIndexSequence2[-window :]).unsqueeze(0).to(device)\n",
    "output2 = network(example2)\n",
    "predict_index2 = output2.argmax(dim=1, keepdim=True)\n",
    "stringIndexSequence2.append(predict_index2.item())\n",
    "predict_char2 = YuChuLi.indexToCharTransform(stringIndexSequence2, indexToCharVocabulary)\n",
    "predict_char2 = ''.join(predict_char2)\n",
    "print(predict_char2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
